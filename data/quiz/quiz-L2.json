{
  "level": 2,
  "name": "Good",
  "questions": [
    {
      "id": "L2-001",
      "q": "What's the most important first step when preparing to use AI for a task?",
      "options": ["Find a template prompt that worked for someone else", "Clarify your goal and what information the AI needs", "Choose between different AI models and platforms", "Think about how to verify the AI's eventual output"],
      "answer": 1,
      "explanation": "Before using AI, the most critical step is clarifying your objective and identifying what context or information the AI will need to help you effectively."
    },
    {
      "id": "L2-002",
      "q": "Which statement about AI accuracy is correct?",
      "options": ["Well-structured prompts guarantee accurate responses", "AI errors mainly come from user prompting mistakes", "AI can be confidently wrong due to training limits", "Premium AI subscriptions eliminate accuracy issues"],
      "answer": 2,
      "explanation": "AI can produce incorrect information with high confidence — a phenomenon known as hallucination — due to limitations in its training data and architecture."
    },
    {
      "id": "L2-003",
      "q": "Why does providing context in a prompt matter?",
      "options": ["It makes the prompt longer which improves quality", "It helps the AI understand your specific situation", "It's required by most AI platforms to work", "It prevents the AI from asking follow-up questions"],
      "answer": 1,
      "explanation": "Context helps the AI understand your specific situation, needs, and constraints, leading to more relevant and useful responses."
    },
    {
      "id": "L2-004",
      "q": "What is a 'hallucination' in AI terms?",
      "options": ["When AI refuses to answer your question", "When AI generates false information confidently", "When AI takes too long to respond", "When AI misunderstands your language"],
      "answer": 1,
      "explanation": "An AI hallucination occurs when the model generates plausible-sounding but factually incorrect information with apparent confidence."
    },
    {
      "id": "L2-005",
      "q": "A good prompt should include:",
      "options": ["As many words as possible for clarity", "Technical jargon to sound professional", "Clear instructions about what you want", "Multiple unrelated questions at once"],
      "answer": 2,
      "explanation": "Effective prompts contain clear, specific instructions about what you want the AI to produce, including format, tone, and any constraints."
    },
    {
      "id": "L2-006",
      "q": "When AI gives you an answer with specific statistics, you should:",
      "options": ["Trust it if the AI sounds confident", "Verify the information from other sources", "Assume it's accurate if the AI is reputable", "Only trust round numbers like 50% or 100%"],
      "answer": 1,
      "explanation": "AI-generated statistics should always be verified against reliable sources, as models can fabricate specific numbers that sound plausible but are inaccurate."
    },
    {
      "id": "L2-007",
      "q": "What makes natural language prompting effective?",
      "options": ["Using formal academic language only", "AI understands conversational requests well", "Natural language is processed faster", "It requires less computing power"],
      "answer": 1,
      "explanation": "Modern AI models are specifically trained to understand natural, conversational language, making plain-language prompts effective for communication."
    },
    {
      "id": "L2-008",
      "q": "If AI output isn't what you wanted, the best approach is to:",
      "options": ["Accept it and work with what you got", "Refine your prompt with more specific details", "Try a completely different AI platform", "Report the AI for giving wrong answers"],
      "answer": 1,
      "explanation": "Iterative refinement — adjusting your prompt with more specific details, context, or constraints — is the most effective way to improve AI output quality."
    },
    {
      "id": "L2-009",
      "q": "Why is specifying tone in a prompt helpful?",
      "options": ["It makes the AI work harder on the response", "It shapes how the content reads and feels", "It's required for the AI to respond", "It reduces the response length"],
      "answer": 1,
      "explanation": "Specifying tone (e.g., professional, casual, empathetic) guides the AI's writing style to match your intended audience and purpose."
    },
    {
      "id": "L2-010",
      "q": "The main purpose of prompting frameworks like CRISP is to:",
      "options": ["Make AI responses longer and more detailed", "Provide structure for including key information", "Bypass AI safety restrictions", "Make prompts work on all AI platforms equally"],
      "answer": 1,
      "explanation": "Prompting frameworks like CRISP provide a structured checklist to ensure you include the key elements (Context, Role, Instructions, Specifics, Parameters) that improve response quality."
    },
    {
      "id": "L2-011",
      "q": "What is 'prompt engineering'?",
      "options": ["Building physical hardware for AI systems", "The skill of crafting effective instructions for AI", "Programming AI models from scratch", "Engineering AI to respond faster"],
      "answer": 1,
      "explanation": "Prompt engineering is the practice of designing and refining instructions (prompts) to get the best possible outputs from AI models."
    },
    {
      "id": "L2-012",
      "q": "Why should you specify the desired format in your prompt?",
      "options": ["AI cannot respond without a format instruction", "It helps the AI structure its response to match your needs", "Formatted responses are always more accurate", "It reduces the cost of using AI"],
      "answer": 1,
      "explanation": "Specifying format (bullet points, table, paragraph, etc.) helps the AI structure its response in a way that is immediately useful for your purpose."
    },
    {
      "id": "L2-013",
      "q": "What is the difference between a vague and a specific prompt?",
      "options": ["Vague prompts get better creative results", "Specific prompts include details about what, how, and for whom", "There is no real difference in output quality", "Specific prompts take longer for AI to process"],
      "answer": 1,
      "explanation": "Specific prompts include clear details about what you want, how it should be formatted, and who it is for — producing more targeted, useful responses."
    },
    {
      "id": "L2-014",
      "q": "When AI provides a list of facts, you should treat them as:",
      "options": ["Verified truth since AI is trained on reliable data", "Starting points that need verification from reliable sources", "Completely unreliable and useless information", "Accurate if the AI provides sources alongside them"],
      "answer": 1,
      "explanation": "AI-generated facts should be treated as starting points requiring verification — even when they sound authoritative, they may contain fabricated details."
    },
    {
      "id": "L2-015",
      "q": "What does 'iterative prompting' mean?",
      "options": ["Asking the same question to multiple AI tools", "Gradually refining your prompt based on each response", "Writing prompts in a programming language", "Sending the same prompt repeatedly until you get a good answer"],
      "answer": 1,
      "explanation": "Iterative prompting means reviewing each AI response and adjusting your prompt to be more specific, clear, or differently structured to improve results."
    },
    {
      "id": "L2-016",
      "q": "Adding 'explain this for a 10-year-old' to your prompt is an example of:",
      "options": ["Making the AI less intelligent", "Controlling the complexity and reading level of the output", "An invalid instruction that AI will ignore", "Restricting the AI to only use simple vocabulary"],
      "answer": 1,
      "explanation": "Specifying the audience or reading level helps the AI adjust its vocabulary, examples, and complexity to match — producing more accessible content."
    },
    {
      "id": "L2-017",
      "q": "Why might the same prompt produce different results each time?",
      "options": ["The AI is malfunctioning", "AI generation involves randomness that produces variation", "Different users get different quality responses", "The AI is learning from each interaction"],
      "answer": 1,
      "explanation": "AI text generation involves a degree of randomness (controlled by temperature settings), so the same prompt can produce different but related outputs each time."
    },
    {
      "id": "L2-018",
      "q": "What is a 'follow-up prompt'?",
      "options": ["A prompt you use to end a conversation with AI", "An additional prompt that builds on a previous AI response", "The first prompt in any new conversation", "A prompt that follows a specific template exactly"],
      "answer": 1,
      "explanation": "A follow-up prompt builds on the previous response, allowing you to refine, expand, or redirect the AI's output within the same conversation."
    },
    {
      "id": "L2-019",
      "q": "What role does 'specificity' play in prompting?",
      "options": ["More specific prompts always lead to longer responses", "Specificity helps the AI narrow down to exactly what you need", "Being too specific confuses the AI", "Specificity only matters for technical topics"],
      "answer": 1,
      "explanation": "Specificity gives the AI clear boundaries and targets, helping it focus on exactly what you need rather than generating broad, generic content."
    },
    {
      "id": "L2-020",
      "q": "Which is an example of providing context in a prompt?",
      "options": ["'Write something good'", "'I am a marketing manager writing a product launch email for our B2B software'", "'Make it professional'", "'Use your best judgment'"],
      "answer": 1,
      "explanation": "Context includes who you are, what you are working on, and why — this helps the AI tailor its response to your actual situation and needs."
    },
    {
      "id": "L2-021",
      "q": "What is 'prompt clarity'?",
      "options": ["Using the fewest possible words in your prompt", "Ensuring your instructions are unambiguous and easy to follow", "Making your prompt look visually clean", "Writing prompts in a formal, academic style"],
      "answer": 1,
      "explanation": "Prompt clarity means your instructions are unambiguous — the AI should not have to guess what you mean or choose between multiple interpretations."
    },
    {
      "id": "L2-022",
      "q": "When you ask AI to 'be creative,' you should also:",
      "options": ["Trust whatever creative output it generates", "Provide boundaries like topic, audience, and constraints", "Remove all other instructions from the prompt", "Expect the AI to produce truly original ideas"],
      "answer": 1,
      "explanation": "Even creative tasks benefit from boundaries — specifying topic, audience, tone, and constraints helps channel the AI's creativity in a useful direction."
    },
    {
      "id": "L2-023",
      "q": "What is 'output length control' in prompting?",
      "options": ["The AI automatically choosing the perfect length", "Telling the AI how long or short you want the response", "A setting only available in premium AI plans", "Physically limiting how much the AI can type"],
      "answer": 1,
      "explanation": "You can control output length by specifying constraints like 'in 3 sentences,' 'under 200 words,' or 'a brief summary' in your prompt."
    },
    {
      "id": "L2-024",
      "q": "Why is it helpful to tell AI what NOT to do?",
      "options": ["Negative instructions are always processed first", "It prevents common unwanted behaviors in the response", "AI only understands negative instructions", "It makes the AI more creative by limiting options"],
      "answer": 1,
      "explanation": "Negative constraints (e.g., 'do not include technical jargon' or 'avoid bullet points') help prevent common patterns that do not match your needs."
    },
    {
      "id": "L2-025",
      "q": "What is the benefit of asking AI to 'think about' a topic before answering?",
      "options": ["It gives the AI more processing time", "It encourages the AI to consider multiple angles before responding", "It makes the AI use more computing power for accuracy", "It is a polite way to start any prompt"],
      "answer": 1,
      "explanation": "Asking the AI to consider or think about a topic encourages more thoughtful, comprehensive responses that consider multiple perspectives."
    },
    {
      "id": "L2-026",
      "q": "Which prompt is likely to produce the best email draft?",
      "options": ["'Write an email'", "'Write a professional email to my team about the new remote work policy, keeping it under 200 words and friendly in tone'", "'Write something about remote work for my team'", "'Email about policy changes'"],
      "answer": 1,
      "explanation": "The best prompt includes the purpose (new policy), audience (team), constraints (200 words), and tone (friendly) — giving the AI clear direction."
    },
    {
      "id": "L2-027",
      "q": "What is 'AI literacy'?",
      "options": ["The AI's ability to read and write", "Understanding how AI works, its capabilities, and its limitations", "Being able to program AI systems from scratch", "Knowing the names of all AI companies and products"],
      "answer": 1,
      "explanation": "AI literacy means understanding how AI works, what it can and cannot do, and how to use it effectively and responsibly — a critical skill for everyone."
    },
    {
      "id": "L2-028",
      "q": "When asking AI to help with research, you should:",
      "options": ["Accept all facts as verified and cite the AI as your source", "Use AI findings as leads and verify them with primary sources", "Only research topics the AI was specifically trained on", "Avoid AI for research since it cannot access current data"],
      "answer": 1,
      "explanation": "AI can help identify key concepts and generate research leads, but all factual claims should be verified against primary and authoritative sources."
    },
    {
      "id": "L2-029",
      "q": "What happens when you give AI contradictory instructions?",
      "options": ["The AI always follows the first instruction", "The AI may produce confused, inconsistent, or unpredictable output", "The AI will ask you to clarify before responding", "Contradictory instructions cancel each other out"],
      "answer": 1,
      "explanation": "Contradictory instructions confuse the AI, often leading to inconsistent output that partially follows both instructions — always ensure your prompt is coherent."
    },
    {
      "id": "L2-030",
      "q": "Why is AI not a replacement for subject matter experts?",
      "options": ["AI is too expensive for professional use", "AI lacks real-world experience, professional judgment, and accountability", "AI only works for simple, non-professional tasks", "Subject matter experts are faster than AI"],
      "answer": 1,
      "explanation": "AI lacks the real-world experience, professional judgment, ethical accountability, and situational awareness that human subject matter experts bring to complex decisions."
    },
    {
      "id": "L2-031",
      "q": "What does 'garbage in, garbage out' mean for AI?",
      "options": ["AI produces waste data that should be discarded", "Poor-quality prompts lead to poor-quality responses", "AI cannot process messy or unformatted data", "Old AI models produce outdated information"],
      "answer": 1,
      "explanation": "'Garbage in, garbage out' means the quality of AI output directly depends on the quality of the input — vague, poorly structured prompts yield weak results."
    },
    {
      "id": "L2-032",
      "q": "What is 'role assignment' in prompting?",
      "options": ["Creating a user account with a specific role", "Telling the AI to act as a specific expert or character", "Assigning different tasks to different AI models", "Giving the AI administrative permissions"],
      "answer": 1,
      "explanation": "Role assignment tells the AI to adopt a specific perspective or expertise (e.g., 'act as a financial advisor'), shaping its vocabulary and approach."
    },
    {
      "id": "L2-033",
      "q": "When is it appropriate to use AI-generated content directly?",
      "options": ["For any published work without changes", "For internal drafts and brainstorming, with human review before publishing", "Never — AI content should always be rewritten", "Only when the AI confirms its content is accurate"],
      "answer": 1,
      "explanation": "AI-generated content works well for drafts and brainstorming, but should always be reviewed, fact-checked, and refined by a human before publishing."
    },
    {
      "id": "L2-034",
      "q": "What is 'prompt length' and does it matter?",
      "options": ["Longer prompts always produce better results", "Prompt length should match the complexity of the task", "Shorter prompts are always more effective", "Prompt length has no effect on output quality"],
      "answer": 1,
      "explanation": "Prompt length should match task complexity — simple tasks need short prompts while complex tasks benefit from longer, more detailed instructions."
    },
    {
      "id": "L2-035",
      "q": "What is the main risk of using AI for academic writing?",
      "options": ["AI-written papers always receive low grades", "Potential plagiarism, inaccuracies, and violation of academic integrity policies", "AI cannot write in academic styles", "Academic institutions block all AI traffic"],
      "answer": 1,
      "explanation": "Using AI for academic writing risks plagiarism, factual inaccuracies, and violations of academic integrity policies — always understand your institution's guidelines."
    },
    {
      "id": "L2-036",
      "q": "What is 'structured output' from AI?",
      "options": ["Any response that uses complete sentences", "Output organized in a specific format like tables, lists, or JSON", "The AI's internal data structure", "Responses that follow a strict word count"],
      "answer": 1,
      "explanation": "Structured output means AI responses formatted in a specific, organized way — such as tables, bullet lists, JSON, or numbered steps — for easier use."
    },
    {
      "id": "L2-037",
      "q": "If you want AI to compare two things, your prompt should:",
      "options": ["Just name the two things and let AI decide what to compare", "Specify the criteria for comparison and the desired format", "Ask separate questions about each thing individually", "Use only one sentence to keep it simple"],
      "answer": 1,
      "explanation": "Specifying comparison criteria (e.g., cost, features, ease of use) and format (table, pros/cons) produces a focused, useful comparison."
    },
    {
      "id": "L2-038",
      "q": "What is 'AI-assisted writing'?",
      "options": ["AI writing everything while you watch", "Using AI as a collaborative tool to help draft, edit, and improve your writing", "The AI translating your writing to other languages", "A mode where AI corrects your grammar automatically"],
      "answer": 1,
      "explanation": "AI-assisted writing uses AI as a collaborator — helping with brainstorming, drafting, editing, and improving your writing while you maintain creative control."
    },
    {
      "id": "L2-039",
      "q": "Why might you want to ask AI the same question multiple ways?",
      "options": ["To confuse the AI into giving different answers", "Different phrasings can reveal different perspectives or better responses", "AI gives discounts for repeated questions", "Only one phrasing will produce a correct answer"],
      "answer": 1,
      "explanation": "Different phrasings can activate different parts of the AI's knowledge, revealing new perspectives or producing a more complete, useful answer."
    },
    {
      "id": "L2-040",
      "q": "What is 'prompt injection' at a basic level?",
      "options": ["Injecting code into the AI to make it faster", "Crafting inputs that trick AI into ignoring its instructions", "Adding nutritional supplements to improve AI performance", "A medical procedure performed by AI"],
      "answer": 1,
      "explanation": "Prompt injection is a technique where specially crafted inputs trick the AI into ignoring its original instructions or safety guidelines — a key security concern."
    },
    {
      "id": "L2-041",
      "q": "What does it mean to 'constrain' AI output?",
      "options": ["Physically limiting the AI's computing power", "Setting boundaries on format, length, topic, or style", "Preventing the AI from accessing the internet", "Reducing the AI's response speed"],
      "answer": 1,
      "explanation": "Constraining output means setting clear boundaries — such as format, word count, topic scope, or style — to keep the AI's response focused and useful."
    },
    {
      "id": "L2-042",
      "q": "What is a 'use case' for AI?",
      "options": ["A physical case that holds AI hardware", "A specific scenario or task where AI can be applied effectively", "A legal case involving AI technology", "The packaging AI products come in"],
      "answer": 1,
      "explanation": "A use case is a specific scenario, task, or application where AI can be applied effectively — such as content writing, data analysis, or customer support."
    },
    {
      "id": "L2-043",
      "q": "When AI is 'confidently wrong,' it means:",
      "options": ["The AI is deliberately lying to test you", "The response sounds authoritative but contains incorrect information", "The AI has high confidence correctly calibrated", "The response failed to generate properly"],
      "answer": 1,
      "explanation": "AI can present false information in a highly confident, authoritative tone — making verification essential since confidence does not equal correctness."
    },
    {
      "id": "L2-044",
      "q": "What is the value of reviewing AI responses before using them?",
      "options": ["There is no value if you trust the AI model", "It catches errors, hallucinations, and ensures the output fits your needs", "It only matters for technical or scientific content", "Review is only needed for free AI tools, not paid ones"],
      "answer": 1,
      "explanation": "Reviewing AI responses catches factual errors, hallucinations, tone mismatches, and formatting issues — ensuring the output is accurate and fit for purpose."
    },
    {
      "id": "L2-045",
      "q": "What is 'prompt refinement'?",
      "options": ["Making a prompt look more elegant and professional", "Adjusting and improving your prompt based on AI response quality", "Removing all unnecessary words from a prompt", "A premium feature available in paid AI tools"],
      "answer": 1,
      "explanation": "Prompt refinement means analyzing the AI's response and iteratively adjusting your prompt — adding details, changing structure, or clarifying — to improve results."
    },
    {
      "id": "L2-046",
      "q": "Why is it useful to tell AI your purpose or goal?",
      "options": ["AI requires a purpose statement to function", "It helps the AI prioritize relevant information and format the response appropriately", "The AI stores your goals to personalize future sessions", "It makes the AI more motivated to give good answers"],
      "answer": 1,
      "explanation": "Stating your purpose helps the AI understand what outcome you need, so it can prioritize the most relevant information and choose the right format."
    },
    {
      "id": "L2-047",
      "q": "When asking AI for advice, it's important to remember that:",
      "options": ["AI advice is always objective and unbiased", "AI advice reflects patterns in training data, not professional judgment", "AI gives better advice than human professionals", "AI advice comes with legal guarantees of accuracy"],
      "answer": 1,
      "explanation": "AI advice is based on patterns in training data, not professional expertise or understanding of your unique situation — it should supplement, not replace, professional guidance."
    },
    {
      "id": "L2-048",
      "q": "What is a 'conversation thread' with AI?",
      "options": ["A physical wire connecting to the AI server", "A sequence of back-and-forth messages building on each other", "A single one-time message with no follow-up", "A thread of code that runs the AI"],
      "answer": 1,
      "explanation": "A conversation thread is a sequence of messages where each prompt and response builds on previous context, allowing deeper exploration of a topic."
    },
    {
      "id": "L2-049",
      "q": "What does 'AI transparency' mean for users?",
      "options": ["Being able to see through the AI's physical hardware", "Understanding how the AI works, its limitations, and when it's being used", "The AI showing its source code to every user", "Making the AI interface invisible on screen"],
      "answer": 1,
      "explanation": "AI transparency means users can understand how the AI reaches conclusions, what its limitations are, and when AI (vs. humans) is providing information."
    },
    {
      "id": "L2-050",
      "q": "What is 'cross-checking' AI information?",
      "options": ["Having two AI models argue with each other", "Verifying AI output against multiple independent sources", "Checking the AI's response for cross-references", "A security feature that prevents unauthorized AI access"],
      "answer": 1,
      "explanation": "Cross-checking means verifying AI-generated information against multiple independent, reliable sources to confirm accuracy before relying on it."
    },
    {
      "id": "L2-051",
      "q": "Why should you avoid sharing confidential work data with public AI tools?",
      "options": ["AI tools charge extra for processing confidential data", "Your data could be stored, used for training, or exposed in a breach", "AI tools cannot process confidential information", "Confidential data makes the AI give worse responses"],
      "answer": 1,
      "explanation": "Data shared with public AI tools may be stored, used for model training, or exposed in security incidents — handle confidential information with appropriate caution."
    },
    {
      "id": "L2-052",
      "q": "What makes a prompt 'actionable'?",
      "options": ["Including action words like 'do' and 'make'", "Providing enough detail that the AI can produce the exact output you need", "Ending every prompt with an exclamation point", "Using commands instead of questions"],
      "answer": 1,
      "explanation": "An actionable prompt provides sufficient detail — purpose, format, constraints, audience — so the AI can deliver the specific output you need without guessing."
    },
    {
      "id": "L2-053",
      "q": "What is the purpose of a 'system message' in AI applications?",
      "options": ["To display error messages to users", "To set the AI's behavior, role, and constraints before user interaction", "To send messages between different AI systems", "To provide system updates about the AI platform"],
      "answer": 1,
      "explanation": "A system message sets up the AI's behavior, role, and boundaries before any user interaction — it is like giving the AI its job description and rules."
    },
    {
      "id": "L2-054",
      "q": "What is 'information overload' in AI prompting?",
      "options": ["When the AI generates too much text", "Providing so much detail that the AI loses focus on the core task", "When the AI's servers are overloaded with requests", "Reading too many AI-generated responses in one session"],
      "answer": 1,
      "explanation": "Information overload in prompting means providing so much context or so many instructions that the AI loses focus on the core task — balance is key."
    },
    {
      "id": "L2-055",
      "q": "What is 'multi-modal AI'?",
      "options": ["AI that only works in one mode at a time", "AI that can process multiple types of input like text, images, and audio", "AI with multiple different moods", "AI that requires multiple devices to operate"],
      "answer": 1,
      "explanation": "Multi-modal AI can process and generate multiple types of content — such as text, images, audio, and video — within a single model."
    },
    {
      "id": "L2-056",
      "q": "When you say 'act as a teacher,' the AI will:",
      "options": ["Gain actual teaching qualifications and knowledge", "Adjust its tone, explanations, and vocabulary to be educational", "Connect to a database of educational resources", "Refuse tasks that are not education-related"],
      "answer": 1,
      "explanation": "Role prompting like 'act as a teacher' adjusts the AI's communication style — it uses more explanations, simpler language, and educational framing."
    },
    {
      "id": "L2-057",
      "q": "What is the difference between a prompt and a query?",
      "options": ["There is no difference, they are the same thing", "A prompt gives instructions and context, while a query is a simple question", "A query is more advanced than a prompt", "Prompts are for AI and queries are for search engines only"],
      "answer": 1,
      "explanation": "A prompt typically includes instructions, context, and constraints for AI, while a query is a simpler question — prompts guide the AI more deliberately."
    },
    {
      "id": "L2-058",
      "q": "Why is 'verification' a key AI literacy skill?",
      "options": ["Because AI companies require users to verify responses", "Because AI can generate plausible-sounding false information", "Because verification makes the AI work harder next time", "Because unverified responses get deleted automatically"],
      "answer": 1,
      "explanation": "Verification is essential because AI can generate convincing but false information — developing the habit of checking claims is a critical AI literacy skill."
    },
    {
      "id": "L2-059",
      "q": "What does it mean to 'set constraints' in a prompt?",
      "options": ["Restricting which AI model you use", "Defining boundaries like word count, format, topics to avoid, or style", "Locking the AI so only you can use it", "Adding passwords to your prompt for security"],
      "answer": 1,
      "explanation": "Setting constraints means defining specific boundaries — such as word count, format requirements, topics to exclude, or writing style — to focus the AI's output."
    },
    {
      "id": "L2-060",
      "q": "What is the risk of asking AI to write an entire essay for you?",
      "options": ["The essay will always be poorly written", "You may miss learning opportunities and risk academic integrity violations", "AI cannot write essays longer than 500 words", "The essay will be flagged as AI-generated by every reader"],
      "answer": 1,
      "explanation": "Having AI write entire essays means you miss the learning process and risk academic integrity violations — use AI to assist your thinking, not replace it."
    },
    {
      "id": "L2-061",
      "q": "What is 'AI-generated content' (AIGC)?",
      "options": ["Content that was manually typed by AI researchers", "Text, images, code, or other media created by AI models", "Content about AI that humans write", "Government regulations about AI content"],
      "answer": 1,
      "explanation": "AI-generated content (AIGC) is any text, image, code, audio, or video created by AI models in response to prompts or automated processes."
    },
    {
      "id": "L2-062",
      "q": "When using AI for brainstorming, a good approach is to:",
      "options": ["Accept the first idea the AI generates", "Ask for multiple ideas, then evaluate and refine the best ones", "Only use AI brainstorming for trivial topics", "Have the AI pick the best idea for you"],
      "answer": 1,
      "explanation": "Effective AI brainstorming involves generating multiple ideas, then using your judgment to evaluate, combine, and refine the most promising options."
    },
    {
      "id": "L2-063",
      "q": "What does 'scope' mean in the context of an AI prompt?",
      "options": ["The magnification level of the AI's analysis", "The boundaries defining what the AI should and shouldn't cover", "The range of AI models available for the task", "The telescope used to view AI processing"],
      "answer": 1,
      "explanation": "Scope defines the boundaries of what the AI should address — keeping scope focused prevents overly broad, unfocused responses."
    },
    {
      "id": "L2-064",
      "q": "Why is it important to understand AI's limitations?",
      "options": ["So you can complain effectively to AI companies", "So you can set realistic expectations and use AI appropriately", "Because limitations make AI less useful", "So you can avoid using AI entirely"],
      "answer": 1,
      "explanation": "Understanding AI limitations helps you set realistic expectations, identify when to verify outputs, and know when human expertise is needed instead."
    },
    {
      "id": "L2-065",
      "q": "What is 'response quality' in AI?",
      "options": ["How fast the AI responds to your prompt", "How accurate, relevant, and useful the AI's output is", "The resolution of images the AI generates", "The grammar score of the AI's text"],
      "answer": 1,
      "explanation": "Response quality measures how accurate, relevant, well-structured, and useful the AI's output is relative to what was requested."
    },
    {
      "id": "L2-066",
      "q": "What is the 'audience' consideration in prompting?",
      "options": ["How many people will see your prompt", "Specifying who will read the AI's output so it adjusts complexity and tone", "The audience watching you use AI", "The number of AI models processing your prompt"],
      "answer": 1,
      "explanation": "Audience specification tells the AI who the content is for — enabling it to adjust vocabulary, tone, complexity, and examples to match the reader."
    },
    {
      "id": "L2-067",
      "q": "When should you break a complex request into multiple prompts?",
      "options": ["Never — one long prompt is always better", "When the task has multiple distinct parts that need different handling", "Only when using free AI tools with short limits", "When the AI refuses to complete your single prompt"],
      "answer": 1,
      "explanation": "Breaking complex tasks into focused sub-prompts lets you give each part proper attention and constraints, producing better results than one overwhelming prompt."
    },
    {
      "id": "L2-068",
      "q": "What is 'critical thinking' in the context of using AI?",
      "options": ["Criticizing everything the AI produces", "Analyzing AI output for accuracy, logic, and relevance before accepting it", "Thinking about which AI platform is the best", "Only using AI for critical or emergency situations"],
      "answer": 1,
      "explanation": "Critical thinking with AI means actively evaluating output for accuracy, logical consistency, relevance, and potential bias — not passively accepting it."
    },
    {
      "id": "L2-069",
      "q": "What does 'task decomposition' mean for AI users?",
      "options": ["Letting the AI break down tasks on its own", "Breaking a large task into smaller, manageable sub-tasks for AI", "Decomposing old AI tasks that are no longer needed", "Dividing tasks between multiple AI platforms"],
      "answer": 1,
      "explanation": "Task decomposition means breaking a large, complex task into smaller, focused sub-tasks that AI can handle more effectively one at a time."
    },
    {
      "id": "L2-070",
      "q": "What is 'AI disclosure'?",
      "options": ["The AI revealing its source code to users", "Informing others when AI was used to create or assist with content", "Disclosing your personal information to AI systems", "The AI listing all the data it was trained on"],
      "answer": 1,
      "explanation": "AI disclosure means being transparent about when and how AI was used to create or assist with content — a growing ethical and legal expectation."
    },
    {
      "id": "L2-071",
      "q": "Why should you consider the source of AI training data?",
      "options": ["Training data sources are always listed for every AI model", "The quality and diversity of training data affects the AI's accuracy and biases", "Training data sources do not affect the AI's output at all", "Only free AI tools have questionable training data"],
      "answer": 1,
      "explanation": "The quality, diversity, and representativeness of training data directly impacts the AI's accuracy, biases, and reliability on different topics."
    },
    {
      "id": "L2-072",
      "q": "What is 'prompt stacking'?",
      "options": ["Placing multiple prompts on top of each other physically", "Combining multiple instructions into a single prompt", "Using the same prompt across multiple AI models", "Saving prompts in a stack data structure"],
      "answer": 1,
      "explanation": "Prompt stacking combines multiple instructions — such as role, task, format, and constraints — into a single, comprehensive prompt for richer outputs."
    },
    {
      "id": "L2-073",
      "q": "What does 'AI safety' mean?",
      "options": ["Wearing safety goggles when using AI computers", "Ensuring AI systems do not cause harm and operate within intended boundaries", "The safety rating of the physical hardware running AI", "Keeping AI systems locked in secure server rooms"],
      "answer": 1,
      "explanation": "AI safety refers to the research and practices ensuring that AI systems operate within intended boundaries and do not cause unintended harm."
    },
    {
      "id": "L2-074",
      "q": "If you paste a long document into a chat and ask AI to summarize it, you should:",
      "options": ["Trust the summary completely since AI read the entire document", "Check that key points are accurately represented and nothing critical is missing", "Never paste documents because AI cannot handle long text", "Only paste documents that are under 100 words"],
      "answer": 1,
      "explanation": "Always verify AI summaries against the original document — AI can miss nuances, overemphasize minor points, or misrepresent key details."
    },
    {
      "id": "L2-075",
      "q": "What is 'human-in-the-loop' AI?",
      "options": ["AI that tracks human physical activities like running", "A system where humans review and approve AI decisions before they take effect", "Humans who are trapped in AI processing loops", "AI that loops through human conversations repeatedly"],
      "answer": 1,
      "explanation": "Human-in-the-loop means a human reviews, validates, or approves AI-generated outputs or decisions before they are finalized — maintaining human oversight."
    },
    {
      "id": "L2-076",
      "q": "What is 'feedback' in the context of AI prompting?",
      "options": ["Audio feedback from AI speakers", "Telling the AI what was good or bad about its response to improve the next one", "The AI's internal evaluation of its own output", "Customer reviews of AI products"],
      "answer": 1,
      "explanation": "Providing feedback means telling the AI what worked or did not work in its response, then adjusting your prompt to guide the next output closer to your goal."
    },
    {
      "id": "L2-077",
      "q": "What is 'content moderation' in AI systems?",
      "options": ["Moderating the length of AI responses", "Filtering out harmful, inappropriate, or policy-violating content", "A human moderator typing AI responses", "Adjusting the content's reading level to moderate difficulty"],
      "answer": 1,
      "explanation": "Content moderation uses rules and AI to filter out harmful, inappropriate, or policy-violating content from both inputs and outputs."
    },
    {
      "id": "L2-078",
      "q": "When AI writes code for you, you should:",
      "options": ["Run it immediately without reading it", "Review the code, understand what it does, and test it before using", "Trust it completely if the AI is a well-known brand", "Only use AI-generated code for personal projects, not professional ones"],
      "answer": 1,
      "explanation": "Always review and test AI-generated code — it may contain bugs, security vulnerabilities, or logic errors that could cause serious problems."
    },
    {
      "id": "L2-079",
      "q": "What is 'prompt reusability'?",
      "options": ["Using the same prompt forever without changes", "Creating prompt templates that can be adapted for similar tasks", "Recycling old prompts from other users", "A limit on how many times you can use a prompt"],
      "answer": 1,
      "explanation": "Prompt reusability means designing prompt templates with clear structure that can be adapted for similar tasks — saving time while maintaining quality."
    },
    {
      "id": "L2-080",
      "q": "What is the risk of AI-generated misinformation?",
      "options": ["There is no risk since AI only generates accurate information", "AI can create convincing but false content that spreads as fact", "Misinformation only happens with free AI tools", "AI always warns you when its information is inaccurate"],
      "answer": 1,
      "explanation": "AI can generate highly convincing but completely false information that, if shared unchecked, can spread as misinformation — verification is essential."
    },
    {
      "id": "L2-081",
      "q": "What is 'prompt testing'?",
      "options": ["Taking a quiz about how to write prompts", "Trying your prompt multiple times to check consistency and quality", "A paid service that evaluates your prompts", "Testing whether the AI platform is working correctly"],
      "answer": 1,
      "explanation": "Prompt testing means running your prompt multiple times (or with variations) to check whether the AI consistently produces the quality and type of output you need."
    },
    {
      "id": "L2-082",
      "q": "Why might you want AI to generate content in bullet points instead of paragraphs?",
      "options": ["Bullet points use less AI processing power", "Bullets are easier to scan, compare, and extract specific information from", "AI cannot write proper paragraphs", "Bullet points are always better than paragraphs"],
      "answer": 1,
      "explanation": "Bullet points make content easier to scan and extract specific information from — ideal for lists, comparisons, and reference material."
    },
    {
      "id": "L2-083",
      "q": "What is 'fact-checking' AI output?",
      "options": ["The AI checking its own facts internally", "Verifying the AI's claims against authoritative, reliable sources", "A feature built into all AI models", "Asking a different AI to check the first AI's answer"],
      "answer": 1,
      "explanation": "Fact-checking AI output means independently verifying claims against authoritative sources — this is the user's responsibility, not the AI's."
    },
    {
      "id": "L2-084",
      "q": "What is 'response variation' in AI?",
      "options": ["The AI giving different quality responses to different users", "The natural differences in output when the same prompt is run multiple times", "Variations in the AI's response speed", "Different formatting options the AI can use"],
      "answer": 1,
      "explanation": "Response variation is the natural difference in AI output when running the same prompt multiple times, caused by randomness in the generation process."
    },
    {
      "id": "L2-085",
      "q": "When using AI to help write a resume, you should:",
      "options": ["Let AI write the entire resume based on a job title alone", "Provide your real experience and have AI help structure and phrase it", "Use AI to fabricate impressive-sounding accomplishments", "Copy a resume template directly from AI output"],
      "answer": 1,
      "explanation": "Provide your real experience, skills, and achievements — then let AI help structure, phrase, and optimize the content for the target role."
    },
    {
      "id": "L2-086",
      "q": "What does it mean when an AI platform has a 'terms of service'?",
      "options": ["It lists the technical specifications of the AI model", "It outlines the rules and agreements for using the AI service", "It shows the AI's service hours and availability", "It is a legal requirement that no one needs to read"],
      "answer": 1,
      "explanation": "Terms of service outline how the AI platform can and cannot be used, data handling policies, user responsibilities, and other legal agreements."
    },
    {
      "id": "L2-087",
      "q": "What is 'few-shot' prompting at a basic level?",
      "options": ["Using AI for only a few tasks", "Giving the AI examples of what you want before asking it to produce output", "A quick test of the AI with minimal input", "Only sending short prompts of a few words"],
      "answer": 1,
      "explanation": "Few-shot prompting means providing the AI with a few examples of the desired input-output pattern before asking it to produce new output in the same style."
    },
    {
      "id": "L2-088",
      "q": "What is 'responsible disclosure' when using AI?",
      "options": ["The AI disclosing responsible behavior", "Being honest about AI's role in content creation and its limitations", "Only using AI in responsible industries like healthcare", "Disclosing your identity before using AI"],
      "answer": 1,
      "explanation": "Responsible disclosure means being transparent about AI involvement in content creation and honestly representing the limitations of AI-generated material."
    },
    {
      "id": "L2-089",
      "q": "Why is 'plain language' often effective in AI prompts?",
      "options": ["AI cannot understand complex vocabulary", "Clear, everyday language reduces ambiguity and misinterpretation", "Plain language prompts are processed faster", "Only non-technical users should use plain language"],
      "answer": 1,
      "explanation": "Plain language minimizes ambiguity and misinterpretation — clear, straightforward instructions help the AI understand exactly what you mean."
    },
    {
      "id": "L2-090",
      "q": "What should you do before relying on AI for an important decision?",
      "options": ["Ask the AI if it is confident in its answer", "Get multiple perspectives, verify facts, and consult relevant experts", "Choose the most expensive AI platform for better accuracy", "Use AI as your sole decision-making tool for efficiency"],
      "answer": 1,
      "explanation": "Important decisions require multiple perspectives, fact verification, and expert consultation — AI is one input among many, not a sole decision-maker."
    },
    {
      "id": "L2-091",
      "q": "What is 'AI augmentation'?",
      "options": ["Making AI systems physically larger", "Using AI to enhance and extend human capabilities, not replace them", "Augmenting AI with more training data after deployment", "A surgical procedure to connect humans to AI"],
      "answer": 1,
      "explanation": "AI augmentation means using AI to enhance and extend human capabilities — amplifying human intelligence and productivity rather than replacing people."
    },
    {
      "id": "L2-092",
      "q": "What is the best approach when AI gives a partially correct response?",
      "options": ["Accept the response as fully correct", "Identify what is correct, then refine your prompt to fix the incorrect parts", "Discard the entire response and start over", "Report the AI for giving wrong information"],
      "answer": 1,
      "explanation": "When AI gives a partial answer, identify what works, then refine your prompt to address the gaps or inaccuracies — building on what already works."
    },
    {
      "id": "L2-093",
      "q": "What is 'conversational context' in AI?",
      "options": ["The physical context where you are having the conversation", "The accumulation of previous messages that inform the AI's understanding", "A feature that adds background music to AI conversations", "The time of day the conversation takes place"],
      "answer": 1,
      "explanation": "Conversational context is the accumulated information from previous messages in the chat that the AI uses to understand references and maintain coherence."
    },
    {
      "id": "L2-094",
      "q": "What is 'copyrighted content' and how does it relate to AI?",
      "options": ["AI automatically obtains copyright for all content it generates", "Content protected by copyright that AI should not reproduce verbatim", "All AI output is copyrighted by the AI company", "Copyright does not apply to digital content"],
      "answer": 1,
      "explanation": "Copyrighted content is protected creative work — AI should not reproduce it verbatim, and users should be aware of copyright considerations when using AI outputs."
    },
    {
      "id": "L2-095",
      "q": "What is the difference between AI 'training' and AI 'inference'?",
      "options": ["They are two names for the same process", "Training is when the AI learns patterns; inference is when it generates responses", "Training happens after inference", "Inference is the AI's opinion about its training quality"],
      "answer": 1,
      "explanation": "Training is the learning phase where the AI processes data and learns patterns. Inference is the application phase where it uses those patterns to generate responses."
    },
    {
      "id": "L2-096",
      "q": "What is 'AI-generated plagiarism'?",
      "options": ["When AI steals prompts from other users", "Passing off AI-generated content as your own original work", "When one AI copies another AI's responses", "Plagiarism that happens inside the AI during training"],
      "answer": 1,
      "explanation": "AI-generated plagiarism occurs when someone presents AI-generated content as their own original work — an ethical concern in academic and professional settings."
    },
    {
      "id": "L2-097",
      "q": "Why is 'patience' important when learning to prompt effectively?",
      "options": ["AI works better when users are in a patient mood", "Effective prompting is a skill that improves with practice and iteration", "Patient users get priority in the AI processing queue", "The AI detects impatient users and gives worse responses"],
      "answer": 1,
      "explanation": "Prompting is a skill that improves with practice — expect to iterate and refine your approach over time rather than achieving perfect results immediately."
    },
    {
      "id": "L2-098",
      "q": "What does 'data-driven' mean in the context of AI?",
      "options": ["AI that can drive vehicles using data", "AI decisions and outputs are based on patterns found in data", "Storing AI data on external drives", "AI that only works with numerical data"],
      "answer": 1,
      "explanation": "Data-driven means the AI's outputs and decisions are based on patterns, correlations, and relationships found in the data it was trained on."
    },
    {
      "id": "L2-099",
      "q": "When AI generates a list of steps, you should:",
      "options": ["Follow them exactly without any modifications", "Evaluate each step for accuracy, feasibility, and relevance to your situation", "Only follow the first three steps", "Reverse the order since AI lists are often backwards"],
      "answer": 1,
      "explanation": "Evaluate each step for accuracy and relevance — AI-generated instructions may need adaptation, reordering, or supplementation for your specific situation."
    },
    {
      "id": "L2-100",
      "q": "The key takeaway for Good-level prompting is:",
      "options": ["Always use the longest possible prompt", "Be clear, provide context, and always verify AI output", "Trust AI completely once you learn to prompt well", "The AI model matters more than the prompt quality"],
      "answer": 1,
      "explanation": "Good-level prompting combines clarity, context, and verification — these fundamentals form the foundation for all advanced prompting techniques."
    }
  ]
}