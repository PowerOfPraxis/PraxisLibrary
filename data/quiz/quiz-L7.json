{
  "level": 7,
  "name": "Master",
  "questions": [
    {"id": "L7-001", "q": "What is Cursor?", "options": ["A text cursor for typing", "An AI-first code editor built on VS Code", "A mouse pointer customization tool", "A database management system"], "answer": 1, "explanation": "Cursor is an AI-first code editor built on VS Code that integrates AI assistance directly into the development workflow for writing, editing, and understanding code."},
    {"id": "L7-002", "q": "What is an IDE?", "options": ["Internet Data Exchange", "Integrated Development Environment", "Intelligent Design Editor", "Internal Document Engine"], "answer": 1, "explanation": "An IDE (Integrated Development Environment) is a software application that combines code editing, debugging, building, and testing tools in a single interface."},
    {"id": "L7-003", "q": "Which AI coding assistant is built by Anthropic?", "options": ["GitHub Copilot", "Codeium", "Claude Code", "Amazon CodeWhisperer"], "answer": 2, "explanation": "Claude Code is Anthropic's AI coding assistant, built on the Claude model family, designed for code generation, analysis, and development workflows."},
    {"id": "L7-004", "q": "When combining CRISP with Chain-of-Thought, you should:", "options": ["Only use one method at a time, never combine", "Add 'think step by step' to your CRISP prompt", "Replace all CRISP elements with reasoning steps", "Use CRISP for simple tasks and CoT for complex ones only"], "answer": 1, "explanation": "CRISP and Chain-of-Thought complement each other — structure your prompt with CRISP elements, then add 'think step by step' in the Instructions to get reasoned responses."},
    {"id": "L7-005", "q": "Constrained Output Formats (like JSON) are essential for:", "options": ["Making responses look professional", "Programmatic use of AI outputs", "Reducing AI response time", "Improving AI creativity"], "answer": 1, "explanation": "Constrained output formats like JSON ensure AI responses follow a predictable schema that can be parsed and used programmatically by downstream applications."},
    {"id": "L7-006", "q": "How can you use ReAct for debugging code with AI?", "options": ["Ask AI to rewrite all the code from scratch", "Request diagnostic steps with Thought, Action, Observation", "Only share error messages, not context", "Let AI guess what the problem might be"], "answer": 1, "explanation": "Using ReAct for debugging means asking the AI to think about the problem, take diagnostic actions (inspect code, trace logic), and observe results iteratively."},
    {"id": "L7-007", "q": "When using AI in VS Code or Cursor, prompting skills help you:", "options": ["Type faster with autocomplete", "Get better code suggestions and explanations", "Change the editor's color theme", "Install extensions automatically"], "answer": 1, "explanation": "Strong prompting skills help you get more relevant code suggestions, better explanations, and more effective assistance from AI-powered IDE features."},
    {"id": "L7-008", "q": "Prompt chaining means:", "options": ["Using very long prompts", "Linking multiple prompts where output feeds the next", "Chaining words together without spaces", "Repeating the same prompt multiple times"], "answer": 1, "explanation": "Prompt chaining links multiple prompts in sequence, where the output of one prompt becomes the input for the next — enabling complex multi-step workflows."},
    {"id": "L7-009", "q": "For complex multi-step tasks, the most effective approach is to:", "options": ["Write one very detailed prompt", "Break it into smaller prompts and combine methods", "Let AI figure out the steps on its own", "Only use the simplest prompting framework"], "answer": 1, "explanation": "Breaking complex tasks into smaller prompts and combining methods (e.g., CRISP + CoT + chaining) produces better results than trying to fit everything into one prompt."},
    {"id": "L7-010", "q": "A 'Master' level prompter would likely:", "options": ["Only use templates from the internet", "Combine frameworks, use IDEs, and verify AI outputs", "Trust AI completely without verification", "Avoid using advanced techniques"], "answer": 1, "explanation": "Master-level prompters combine multiple frameworks strategically, leverage AI-powered IDEs, and always verify AI outputs — they understand both the capabilities and limitations."},
    {"id": "L7-011", "q": "In Cursor, what does the Cmd+K (or Ctrl+K) shortcut typically do?", "options": ["Open the AI inline editing prompt", "Delete the current line", "Toggle the file explorer", "Run the current file"], "answer": 0, "explanation": "In Cursor, Cmd+K (Ctrl+K on Windows/Linux) opens the AI inline editing prompt, allowing you to describe code changes in natural language and have the AI apply them directly in the editor."},
    {"id": "L7-012", "q": "What is a key advantage of Cursor's 'Composer' feature?", "options": ["It plays background music while coding", "It formats code according to Prettier rules", "It can make coordinated edits across multiple files simultaneously", "It automatically deploys code to production"], "answer": 2, "explanation": "Cursor's Composer feature can make coordinated changes across multiple files at once, understanding the relationships between files and ensuring consistency across the codebase."},
    {"id": "L7-013", "q": "What is the '.cursorrules' file used for?", "options": ["Defining syntax highlighting rules", "Configuring keyboard shortcuts", "Managing Git merge conflicts", "Setting project-specific AI instructions and coding standards"], "answer": 3, "explanation": "The .cursorrules file lets developers define project-specific instructions for Cursor's AI, including coding conventions, preferred patterns, and context about the project architecture."},
    {"id": "L7-014", "q": "Claude Code operates primarily through which interface?", "options": ["A graphical desktop application", "A web browser extension", "A command-line interface (CLI)", "A mobile application"], "answer": 2, "explanation": "Claude Code is Anthropic's CLI-based coding assistant that runs in the terminal, allowing developers to interact with Claude directly from their command line for code generation, analysis, and editing tasks."},
    {"id": "L7-015", "q": "What is the purpose of the CLAUDE.md file in a project using Claude Code?", "options": ["It provides project-specific instructions read at the start of every session", "It stores API keys for authentication", "It logs all previous conversations", "It configures the Claude model version"], "answer": 0, "explanation": "The CLAUDE.md file contains project-specific instructions, coding standards, and context that Claude Code reads automatically at the start of every session, ensuring consistent behavior aligned with project requirements."},
    {"id": "L7-016", "q": "In a prompt chain for code review, what should the first link typically do?", "options": ["Write the final report immediately", "Deploy the code to a test environment", "Analyze the code and identify areas of concern", "Delete all comments from the code"], "answer": 2, "explanation": "The first link in a code review chain should analyze the code and identify areas of concern, producing structured findings that subsequent links can use for deeper analysis, prioritization, and report generation."},
    {"id": "L7-017", "q": "When combining few-shot examples with a structured output format, the examples should:", "options": ["Be written in a completely different format than requested", "Only show incorrect examples", "Use plain text instead of the requested format", "Demonstrate the exact output schema you expect"], "answer": 3, "explanation": "Few-shot examples should demonstrate the exact output schema you expect. This teaches the AI both the content pattern and the structural format simultaneously, reducing errors in the response."},
    {"id": "L7-018", "q": "What is 'context window management' in multi-step AI workflows?", "options": ["Strategically controlling what information the AI sees at each step", "Arranging physical windows on your monitor", "Closing browser tabs to save memory", "Setting a timer for each prompt"], "answer": 0, "explanation": "Context window management means strategically controlling what information is passed to the AI at each step of a workflow, ensuring relevant context is included while avoiding token limits and information overload."},
    {"id": "L7-019", "q": "In VS Code, the GitHub Copilot Chat panel allows you to:", "options": ["Only autocomplete single lines of code", "Manage GitHub repository settings", "Have conversational interactions about your codebase with AI", "Edit images directly in the editor"], "answer": 2, "explanation": "GitHub Copilot Chat in VS Code provides a conversational interface where developers can ask questions about code, request explanations, generate code, and get help with debugging through natural language dialogue."},
    {"id": "L7-020", "q": "What distinguishes an 'agentic' AI coding workflow from a simple prompt-response?", "options": ["It uses more expensive API calls", "It only works with Python code", "It requires an internet connection at all times", "The AI can autonomously plan, execute steps, and iterate based on results"], "answer": 3, "explanation": "Agentic workflows allow the AI to autonomously plan steps, execute them (like running commands, reading files, making edits), observe results, and iterate — going beyond single prompt-response exchanges."},
    {"id": "L7-021", "q": "When chaining prompts for data analysis, a good intermediate step is to:", "options": ["Have the AI summarize and validate findings before proceeding", "Skip validation and move to visualization", "Combine all steps into one massive prompt", "Only analyze the first row of data"], "answer": 0, "explanation": "Including a validation step in your prompt chain where the AI summarizes and verifies intermediate findings helps catch errors early and ensures subsequent steps build on accurate analysis."},
    {"id": "L7-022", "q": "Cursor's 'Tab' completion differs from traditional autocomplete because it:", "options": ["Only suggests variable names", "Replaces the entire file content", "Can predict and generate multi-line code edits based on context", "Only works with JavaScript"], "answer": 2, "explanation": "Cursor's Tab completion goes beyond traditional autocomplete by predicting and generating multi-line code changes based on the surrounding context, recent edits, and the developer's apparent intent."},
    {"id": "L7-023", "q": "What is a 'system prompt' in the context of AI IDE integrations?", "options": ["An error message from the operating system", "A prompt that only works on Linux systems", "The first message a user types", "Background instructions that define the AI's behavior and constraints"], "answer": 3, "explanation": "A system prompt provides background instructions that define the AI's behavior, role, constraints, and output preferences. In AI IDEs, it shapes how the assistant responds to coding queries and generates code."},
    {"id": "L7-024", "q": "In Claude Code, the '/compact' command is used to:", "options": ["Compress conversation context to free up token space", "Minify the current code file", "Reduce the font size in the terminal", "Archive old project files"], "answer": 0, "explanation": "The /compact command in Claude Code compresses the conversation context, summarizing previous exchanges to free up token space while preserving essential information for continued work."},
    {"id": "L7-025", "q": "When combining role-playing with structured output, a good practice is to:", "options": ["Let the role override the output format", "Never use roles with structured outputs", "Define the role first, then specify the exact output structure", "Use a different AI model for each part"], "answer": 2, "explanation": "Define the expert role first to establish domain knowledge and perspective, then specify the exact output structure. The role informs the content quality while the format ensures machine-readable consistency."},
    {"id": "L7-026", "q": "What is the primary risk of a long prompt chain without validation steps?", "options": ["The AI will refuse to answer", "The prompts will get shorter automatically", "The AI will switch to a different language", "Errors compound across steps, producing unreliable final output"], "answer": 3, "explanation": "Without validation steps, errors in early links compound through subsequent steps (error propagation), meaning a small mistake early on can produce significantly unreliable results at the end of the chain."},
    {"id": "L7-027", "q": "In a multi-step workflow for generating a test suite, what should come before writing tests?", "options": ["Analyzing the code to identify testable behaviors and edge cases", "Running the tests", "Deleting existing test files", "Deploying to production"], "answer": 0, "explanation": "Before writing tests, the AI should analyze the code to identify all testable behaviors, function signatures, edge cases, and dependencies. This analysis step ensures comprehensive test coverage."},
    {"id": "L7-028", "q": "What does '@codebase' do when used in Cursor's chat?", "options": ["Deletes the codebase", "Creates a backup of all files", "Encrypts the source code", "Searches and references the entire project codebase for context"], "answer": 3, "explanation": "The @codebase reference in Cursor's chat triggers a semantic search across the entire project, allowing the AI to find and reference relevant code files, functions, and patterns when answering questions."},
    {"id": "L7-029", "q": "Which approach best handles a complex refactoring task with AI assistance?", "options": ["Ask the AI to refactor everything in one prompt", "Chain prompts: analyze current code, plan changes, implement per-module, then verify", "Only refactor files smaller than 100 lines", "Avoid AI for refactoring entirely"], "answer": 1, "explanation": "Complex refactoring benefits from chained steps: first analyze the current architecture, then plan the refactoring strategy, implement changes module by module, and finally verify that behavior is preserved."},
    {"id": "L7-030", "q": "What is 'prompt decomposition' in the context of complex workflows?", "options": ["Letting prompts expire after a time limit", "Removing words from a prompt to make it shorter", "Breaking a complex task into smaller, focused sub-prompts", "Converting prompts to a different language"], "answer": 2, "explanation": "Prompt decomposition means breaking a complex task into smaller, focused sub-prompts that each handle one aspect. This improves accuracy because each sub-prompt operates within a manageable scope."},
    {"id": "L7-031", "q": "In an AI IDE, what is 'codebase indexing'?", "options": ["Numbering each line of code", "Sorting files alphabetically", "Compressing code files for storage", "Creating a searchable representation of the project for AI context retrieval"], "answer": 3, "explanation": "Codebase indexing creates a searchable, often vector-based, representation of the project's code. This allows the AI to quickly retrieve relevant files and functions when answering questions or generating code."},
    {"id": "L7-032", "q": "When using Claude Code to edit files, it is important to:", "options": ["Review proposed changes before accepting them", "Let the AI make unlimited changes without review", "Only edit files created in the current session", "Disable all version control"], "answer": 0, "explanation": "Always review AI-proposed changes before accepting them. AI can introduce subtle bugs or make unintended modifications. Human review is essential for maintaining code quality and correctness."},
    {"id": "L7-033", "q": "A prompt chain for content creation typically follows which sequence?", "options": ["Edit, Research, Outline, Draft", "Draft, Research, Publish, Outline", "Review, Draft, Delete, Start Over", "Research, Outline, Draft, Review/Edit"], "answer": 3, "explanation": "Effective content creation chains follow: Research (gather information), Outline (organize structure), Draft (generate content), Review/Edit (refine and polish). Each step builds on the previous output."},
    {"id": "L7-034", "q": "What is the benefit of providing file paths when prompting AI in a coding context?", "options": ["It makes the prompt longer", "It gives the AI precise context about which files to read or modify", "File paths are only needed for images", "It automatically backs up those files"], "answer": 1, "explanation": "Providing specific file paths gives the AI precise context about which files to analyze or modify, reducing ambiguity and ensuring the AI works with the correct parts of your codebase."},
    {"id": "L7-035", "q": "In Cursor, what is the purpose of the '.cursorignore' file?", "options": ["Excluding files and directories from AI indexing and context", "Hiding files from the file explorer", "Preventing files from being saved", "Blocking certain keyboard shortcuts"], "answer": 0, "explanation": "The .cursorignore file tells Cursor which files and directories to exclude from AI indexing and context. This is useful for ignoring large generated files, sensitive data, or irrelevant dependencies."},
    {"id": "L7-036", "q": "What makes combining Tree-of-Thought with prompt chaining powerful?", "options": ["It reduces the number of prompts needed to one", "It only works for mathematical problems", "Each chain step can explore multiple solution paths before selecting the best", "It eliminates the need for human review"], "answer": 2, "explanation": "Combining Tree-of-Thought with chaining means each step can explore multiple reasoning paths, evaluate them, and select the best before passing results to the next chain link — improving decision quality at every stage."},
    {"id": "L7-037", "q": "When using AI to orchestrate a CI/CD pipeline, the AI should:", "options": ["Have full production deployment access without restrictions", "Only work with one programming language", "Ignore security considerations for speed", "Suggest configurations and commands that a human reviews before execution"], "answer": 3, "explanation": "AI should suggest CI/CD configurations and commands for human review, never have unrestricted production access. Humans must verify pipeline changes to prevent security risks and unintended deployments."},
    {"id": "L7-038", "q": "What is 'semantic code search' in AI-powered IDEs?", "options": ["Finding code by meaning and intent rather than exact keyword matches", "Searching for exact text matches in file names", "Searching only within comments", "A feature exclusive to web browsers"], "answer": 0, "explanation": "Semantic code search uses AI embeddings to find code by its meaning and intent, not just keyword matches. You can describe what code does in natural language and find relevant implementations."},
    {"id": "L7-039", "q": "In Claude Code, what does the tool-use capability allow?", "options": ["Installing physical hardware tools", "Connecting to third-party payment systems", "The AI can read files, run commands, and make edits as part of its workflow", "Rendering 3D graphics"], "answer": 2, "explanation": "Claude Code's tool-use capability allows the AI to read files from disk, execute terminal commands, search codebases, and make file edits as part of an iterative problem-solving workflow."},
    {"id": "L7-040", "q": "When combining self-consistency with structured output, you should:", "options": ["Generate one answer and accept it immediately", "Use inconsistent formatting across attempts", "Only generate responses in plain text", "Generate multiple responses and select the most frequent or consistent answer"], "answer": 3, "explanation": "Self-consistency combined with structured output means generating multiple structured responses, then comparing them to select the most frequent or consistent answer, reducing the impact of any single erroneous generation."},
    {"id": "L7-041", "q": "What is 'inline diff view' in AI coding tools?", "options": ["A side-by-side or inline comparison of original and AI-proposed code changes", "A view showing differences between two monitors", "A tool for viewing image differences", "A way to see differences between programming languages"], "answer": 0, "explanation": "Inline diff view shows a comparison between the original code and AI-proposed changes, typically with additions in green and deletions in red, allowing developers to review exactly what the AI wants to change."},
    {"id": "L7-042", "q": "A well-designed prompt chain includes error handling by:", "options": ["Ignoring errors and continuing to the next step", "Restarting the entire chain from scratch on any error", "Including validation checks and fallback prompts at critical steps", "Only handling errors in the final step"], "answer": 2, "explanation": "Good prompt chains include validation checks at critical steps and fallback prompts that can handle unexpected outputs, ensuring the chain can recover gracefully rather than propagating errors."},
    {"id": "L7-043", "q": "When using AI to generate database migrations, the safest approach is:", "options": ["Apply generated migrations directly to production", "Only use AI for dropping tables", "Skip migration files and modify the database directly", "Generate, review, test on staging, then apply to production"], "answer": 3, "explanation": "AI-generated database migrations should always be reviewed by a human, tested on a staging environment, and only then applied to production. Database changes are irreversible and require extra caution."},
    {"id": "L7-044", "q": "What is the advantage of Cursor's 'chat with selection' feature?", "options": ["You can highlight specific code and ask the AI questions about just that selection", "It automatically selects all code in the file", "It selects the best AI model for you", "It only works with HTML files"], "answer": 0, "explanation": "Chat with selection lets you highlight specific code and direct AI questions or edit requests to just that portion, giving the AI precise context and reducing irrelevant or off-target responses."},
    {"id": "L7-045", "q": "In a complex workflow combining CRISP, CoT, and few-shot examples, the optimal ordering is:", "options": ["Examples first, then CoT, then CRISP", "CoT only, ignore the other methods", "Randomly mix all elements together", "CRISP structure, few-shot examples within it, CoT instruction at the end"], "answer": 3, "explanation": "Start with CRISP to provide overall structure (Context, Role, Instructions, Scope, Parameters), embed few-shot examples in the Instructions section, and add a CoT directive to encourage step-by-step reasoning."},
    {"id": "L7-046", "q": "What is 'prompt routing' in a multi-step workflow?", "options": ["Sending prompts to a printer", "Routing network traffic through a proxy", "Directing different types of tasks to specialized prompts based on classification", "Translating prompts between languages"], "answer": 2, "explanation": "Prompt routing uses a classifier step to determine the nature of a task, then routes it to a specialized prompt optimized for that task type — ensuring each sub-task gets the most appropriate instructions."},
    {"id": "L7-047", "q": "When using VS Code's AI extensions for code review, you should:", "options": ["Use AI findings as a starting point and apply your own judgment", "Accept all AI suggestions without reading them", "Only review code written by other people", "Disable all other extensions first"], "answer": 0, "explanation": "AI code review findings should be treated as a starting point. Developers must apply their own judgment because AI may produce false positives, miss context-specific issues, or not understand business logic."},
    {"id": "L7-048", "q": "Claude Code's ability to run terminal commands is useful for:", "options": ["Only listing directory contents", "Mining cryptocurrency in the background", "Accessing restricted system files", "Executing tests, builds, and other development commands as part of a workflow"], "answer": 3, "explanation": "Claude Code can run terminal commands to execute tests, build projects, install dependencies, and perform other development tasks, making it an effective tool for end-to-end development workflows."},
    {"id": "L7-049", "q": "In prompt chaining, 'state management' refers to:", "options": ["Managing the physical state of your computer", "Tracking and passing relevant information between chain links", "Storing prompts in a database", "Managing US state-specific regulations"], "answer": 1, "explanation": "State management in prompt chaining means tracking outputs, variables, and context from previous steps and ensuring the right information is passed to each subsequent link in the chain."},
    {"id": "L7-050", "q": "What is a 'meta-prompt' in advanced prompting?", "options": ["A prompt that generates or optimizes other prompts", "A prompt about the weather", "A very short prompt", "A prompt written in a foreign language"], "answer": 0, "explanation": "A meta-prompt is a prompt designed to generate, refine, or optimize other prompts. It operates at a higher level of abstraction, treating prompt engineering itself as the task to be accomplished."},
    {"id": "L7-051", "q": "When using AI IDEs for pair programming, the AI is most effective as:", "options": ["A replacement for all human developers", "An authority that should override developer judgment", "A tool only useful for junior developers", "A collaborative partner that suggests while the human decides"], "answer": 3, "explanation": "AI in pair programming works best as a collaborative partner — generating suggestions, alternatives, and explanations while the human developer makes final decisions based on broader project context and judgment."},
    {"id": "L7-052", "q": "What does 'grounding' mean in the context of AI coding assistants?", "options": ["Connecting the computer to an electrical ground", "Connecting AI responses to actual codebase files and documentation", "Forcing the AI to stay calm", "Running code on bare metal hardware"], "answer": 1, "explanation": "Grounding means ensuring AI responses are connected to actual project files, documentation, and codebase context rather than relying on general training knowledge, which reduces hallucination and increases accuracy."},
    {"id": "L7-053", "q": "A prompt chain for automated testing should include which critical final step?", "options": ["Deleting the tests after running them", "Only running one test case", "Verifying test results and reporting coverage metrics", "Skipping assertion checks"], "answer": 2, "explanation": "The final step in a testing prompt chain should verify test results, check for failures, and report coverage metrics. This validation step ensures the generated tests actually work and provide meaningful coverage."},
    {"id": "L7-054", "q": "In Cursor, the '@file' reference in chat is used to:", "options": ["Delete a specific file", "Rename a file", "Compress a file for email attachment", "Include a specific file's content as context for the AI"], "answer": 3, "explanation": "The @file reference in Cursor's chat includes the specified file's content as context for the AI, allowing you to ask questions about or request changes to specific files without pasting their contents manually."},
    {"id": "L7-055", "q": "When combining methods for API design, a recommended approach is:", "options": ["CRISP for structure, few-shot for endpoint examples, CoT for design rationale", "Use only one framework and ignore the rest", "Skip all frameworks and just describe what you want", "Only provide the API name and let AI decide everything"], "answer": 0, "explanation": "Combining CRISP for overall structure, few-shot examples for demonstrating endpoint patterns, and CoT for reasoning through design decisions produces comprehensive, well-reasoned API designs."},
    {"id": "L7-056", "q": "What is 'prompt templating' in workflow automation?", "options": ["Using decorative borders around prompts", "Copying prompts from the internet", "Creating reusable prompt structures with variable placeholders", "Writing prompts in HTML format"], "answer": 2, "explanation": "Prompt templating creates reusable prompt structures with variable placeholders (like {{code}}, {{language}}) that can be filled dynamically, enabling consistent, automated workflows across different inputs."},
    {"id": "L7-057", "q": "Which is a key difference between Cursor and standard VS Code with Copilot?", "options": ["Cursor cannot run extensions", "VS Code has no AI features at all", "They are exactly the same product", "Cursor deeply integrates AI into editing, navigation, and multi-file changes natively"], "answer": 3, "explanation": "While VS Code uses Copilot as an extension, Cursor is built from the ground up with deep AI integration into editing, navigation, and multi-file changes as native features of the editor itself."},
    {"id": "L7-058", "q": "In Claude Code, what is the purpose of the 'HANDOFF.md' file?", "options": ["It handles file transfers between computers", "It tracks current project state and active tasks across sessions", "It stores handwritten notes as images", "It manages employee onboarding documents"], "answer": 1, "explanation": "HANDOFF.md is a living document that tracks the current project state, active tasks, and recent progress, allowing Claude Code to resume work effectively across different sessions."},
    {"id": "L7-059", "q": "What is 'cascading prompt refinement'?", "options": ["Iteratively refining a prompt based on the AI's previous responses", "Using waterfalls as prompt inspiration", "Making prompts progressively shorter", "A CSS technique for styling prompts"], "answer": 0, "explanation": "Cascading prompt refinement means iteratively improving your prompt based on the AI's responses — each iteration adds clarification, corrects misunderstandings, or adjusts constraints based on what the previous output revealed."},
    {"id": "L7-060", "q": "When orchestrating a multi-step code migration workflow, the first prompt should:", "options": ["Start migrating code immediately", "Delete the old codebase entirely", "Only focus on the UI layer", "Analyze the existing codebase and create an inventory of what needs to change"], "answer": 3, "explanation": "The first step in a migration workflow should analyze the existing codebase to inventory dependencies, patterns, and components that need to change. This assessment informs all subsequent migration steps."},
    {"id": "L7-061", "q": "AI IDE features like 'ghost text' suggestions are most helpful when:", "options": ["They appear after you have finished writing all code", "They predict your next likely code based on current context and patterns", "They suggest code in a language you are not using", "They replace your entire file"], "answer": 1, "explanation": "Ghost text suggestions are most helpful when they accurately predict your next likely code based on the current file context, recent edits, and common patterns — reducing keystrokes while maintaining flow."},
    {"id": "L7-062", "q": "What is a 'guardrail prompt' in a prompt chain?", "options": ["A prompt about highway safety", "A prompt that prevents the AI from responding", "A prompt written in all capital letters", "A validation step that checks AI output against defined constraints before continuing"], "answer": 3, "explanation": "A guardrail prompt is a validation step inserted into a chain that checks the AI's output against defined constraints (format, accuracy, safety) before passing results to the next step, catching problems early."},
    {"id": "L7-063", "q": "When using AI to generate security-sensitive code (authentication, encryption), you must:", "options": ["Review the code against current security standards and test for vulnerabilities", "Trust the AI completely since it knows best practices", "Only use code from Stack Overflow instead", "Implement security features last"], "answer": 0, "explanation": "AI-generated security code must always be reviewed against current security standards and tested for vulnerabilities. AI can produce code with subtle security flaws that appear correct but are exploitable."},
    {"id": "L7-064", "q": "Cursor's '@docs' reference allows you to:", "options": ["Open Microsoft Word documents", "Create new documentation files", "Reference external documentation that the AI can search and cite", "Export code as PDF documents"], "answer": 2, "explanation": "The @docs reference in Cursor allows you to point the AI to external documentation sources that it can search and reference when answering questions, grounding its responses in official documentation."},
    {"id": "L7-065", "q": "In a combined ReAct + Chain-of-Thought approach for debugging, the AI should:", "options": ["Only think about the problem without taking any action", "Immediately rewrite the entire function", "Only observe error messages without reasoning", "Reason about the bug, take diagnostic actions, observe results, then reason again"], "answer": 3, "explanation": "Combining ReAct with CoT means the AI reasons about what might cause the bug (Thought), takes specific diagnostic actions (Action), observes the results (Observation), then reasons again in a productive loop."},
    {"id": "L7-066", "q": "What is the 'fan-out, fan-in' pattern in prompt orchestration?", "options": ["Splitting a task into parallel sub-tasks, then combining their results", "Spreading paper prompts with a fan", "Sending the same prompt to many users", "Gradually increasing prompt complexity"], "answer": 0, "explanation": "Fan-out, fan-in splits a complex task into parallel sub-tasks (fan-out), processes each independently, then combines all results into a unified output (fan-in). This is efficient for tasks with independent components."},
    {"id": "L7-067", "q": "When should you provide your entire codebase as context to an AI coding assistant?", "options": ["Always, for every question", "Never, AI should work without any context", "Rarely — provide only relevant files and let indexing handle broader context", "Only when writing documentation"], "answer": 2, "explanation": "Providing the entire codebase for every query wastes context window tokens and can confuse the AI. Provide relevant files directly and rely on the IDE's indexing features for broader context when needed."},
    {"id": "L7-068", "q": "Claude Code's approach to file editing typically involves:", "options": ["Overwriting entire files without showing changes", "Only editing files smaller than 10 lines", "Requiring manual copy-paste of all changes", "Showing proposed diffs that the user can accept or reject"], "answer": 3, "explanation": "Claude Code typically shows proposed changes as diffs, allowing the user to review additions, deletions, and modifications before accepting them. This maintains human oversight over all code changes."},
    {"id": "L7-069", "q": "In a multi-model prompt chain, different models might be used for:", "options": ["Making the chain more confusing", "Leveraging each model's strengths — fast models for classification, powerful models for generation", "Ensuring no model gets overworked", "Reducing cost by only using free models"], "answer": 1, "explanation": "Multi-model chains strategically use different models for different tasks: fast, cheap models for classification or routing, and more powerful models for complex generation or reasoning — optimizing both cost and quality."},
    {"id": "L7-070", "q": "What is 'context poisoning' in AI coding workflows?", "options": ["Irrelevant or incorrect information in context that degrades AI output quality", "Adding toxic chemicals to your computer", "Using too many programming languages", "A cybersecurity attack on AI models"], "answer": 0, "explanation": "Context poisoning occurs when irrelevant, outdated, or incorrect information is included in the AI's context, leading to degraded output quality. Curating relevant, accurate context is essential for good results."},
    {"id": "L7-071", "q": "When combining persona-based prompting with structured output for code review, you might write:", "options": ["'Review my code, please'", "'Act as a senior security engineer. Analyze this code and output findings as JSON with severity, location, and fix fields'", "'Please be nice when reviewing my code'", "'Output a number from 1 to 10'"], "answer": 1, "explanation": "Combining a specific expert persona with structured output yields focused, actionable results. The persona ensures domain expertise while the JSON structure makes findings parseable and trackable."},
    {"id": "L7-072", "q": "What is the purpose of 'checkpoint prompts' in long workflows?", "options": ["Saving the game in a video game", "Marking lines of code that should not change", "Creating backups of prompt files", "Pausing the chain to verify progress and quality before continuing"], "answer": 3, "explanation": "Checkpoint prompts pause the chain at critical points to verify that accumulated results are correct and on track. If issues are found, the chain can be corrected before investing more effort in subsequent steps."},
    {"id": "L7-073", "q": "VS Code's AI-powered 'Explain Code' feature is most useful when:", "options": ["You want the AI to read your code aloud", "You encounter unfamiliar code and need to understand its logic quickly", "You want to convert code to a different language", "You need to print code on paper"], "answer": 1, "explanation": "The Explain Code feature is most valuable when encountering unfamiliar code — whether from a new codebase, a different team member, or a complex algorithm — providing natural language explanations of what the code does."},
    {"id": "L7-074", "q": "In prompt chaining for document generation, what should the review step check?", "options": ["Factual accuracy, consistency with previous outputs, format compliance, and completeness", "Only spelling errors", "Whether the document is long enough", "Only the first paragraph"], "answer": 0, "explanation": "The review step should check factual accuracy, consistency with information from previous chain steps, compliance with the specified output format, and completeness of coverage — not just surface-level issues."},
    {"id": "L7-075", "q": "What is 'prompt versioning' and why is it important?", "options": ["Numbering your prompts for fun", "Using different versions of an AI model", "Tracking changes to prompts over time to reproduce results and improve systematically", "Writing prompts in different languages"], "answer": 2, "explanation": "Prompt versioning means tracking prompt changes over time with version identifiers. This allows you to reproduce results, compare performance across versions, and systematically improve prompts based on measured outcomes."},
    {"id": "L7-076", "q": "When Cursor's AI suggests a multi-file change, the best practice is to:", "options": ["Accept all changes blindly to save time", "Only accept changes to the smallest files", "Reject all multi-file changes on principle", "Review each file's changes individually, understanding the reasoning"], "answer": 3, "explanation": "Review each file's changes individually to understand what the AI changed and why. Multi-file changes can introduce subtle inconsistencies, and each file may need different levels of scrutiny."},
    {"id": "L7-077", "q": "A 'verification chain' in prompt workflows is used to:", "options": ["Have the AI cross-check its own outputs against source material or constraints", "Verify the user's identity", "Chain multiple users together for verification", "Verify that the internet connection is working"], "answer": 0, "explanation": "A verification chain has the AI cross-check its own outputs against source material, requirements, or constraints. This self-verification catches errors and hallucinations that initial generation might produce."},
    {"id": "L7-078", "q": "What is the benefit of using AI coding assistants for boilerplate code generation?", "options": ["Boilerplate code is the most creative part of coding", "It frees developers to focus on complex logic while AI handles repetitive patterns", "AI-generated boilerplate never needs review", "It eliminates the need for coding standards"], "answer": 1, "explanation": "AI excels at generating repetitive boilerplate code (setup files, CRUD operations, configuration), freeing developers to focus their expertise on complex business logic and architectural decisions."},
    {"id": "L7-079", "q": "In Claude Code, what happens when the context window approaches its limit?", "options": ["The computer crashes", "Nothing, there is no limit", "Claude automatically deletes old files", "Claude may lose track of earlier conversation context, requiring compaction or a new session"], "answer": 3, "explanation": "When the context window fills up, Claude may lose track of earlier conversation details. Using /compact to summarize the conversation or starting a fresh session with updated HANDOFF.md helps maintain effective context."},
    {"id": "L7-080", "q": "What distinguishes a 'sequential chain' from a 'parallel chain' in prompt orchestration?", "options": ["Sequential chains pass output step-by-step; parallel chains run independent tasks simultaneously", "Sequential chains are faster", "There is no difference", "Parallel chains cannot use AI"], "answer": 0, "explanation": "Sequential chains pass each step's output to the next in order (A then B then C). Parallel chains run independent sub-tasks simultaneously (A, B, C at once), then optionally combine results. Each pattern suits different workflow types."},
    {"id": "L7-081", "q": "When combining negative prompting ('do NOT do X') with structured output, you should:", "options": ["Only list what to avoid, never what to do", "Clearly state both what to do AND what to avoid within the structured format specification", "Avoid negative instructions entirely", "Write every instruction as a negative"], "answer": 1, "explanation": "Effective combined prompting states positive instructions alongside specific exclusions within the structured format specification. For example: 'Output JSON with a summary field (max 100 words, do NOT include code snippets).'"},
    {"id": "L7-082", "q": "What is 'retrieval-augmented generation' (RAG) in the context of AI coding tools?", "options": ["A type of clothing brand", "Randomly augmenting generated code", "Fetching relevant code or docs from a knowledge base to include in the AI's context before generation", "A video game technique"], "answer": 2, "explanation": "RAG retrieves relevant code snippets, documentation, or data from a knowledge base and includes them in the AI's context before generating a response. This grounds the output in actual project-specific information."},
    {"id": "L7-083", "q": "In a multi-step workflow for API integration, the correct order of chain steps is:", "options": ["Write code, then read the docs", "Deploy first, test later", "Only write tests, skip implementation", "Read API docs, design the integration, implement code, write tests, verify end-to-end"], "answer": 3, "explanation": "Effective API integration chains follow: read/analyze API documentation, design the integration approach, implement the code, write tests, and verify end-to-end functionality — each step building on the last."},
    {"id": "L7-084", "q": "Cursor's 'Apply' button on AI chat suggestions does what?", "options": ["Takes the AI-suggested code and applies it directly to the relevant file", "Applies for a job at Cursor", "Applies a visual theme to the editor", "Sends the suggestion to your email"], "answer": 0, "explanation": "The Apply button takes code suggested by the AI in the chat panel and applies it directly to the relevant file in the editor, showing a diff so you can review the changes before saving."},
    {"id": "L7-085", "q": "What is the 'map-reduce' pattern in prompt orchestration?", "options": ["A cartography technique", "Breaking input into chunks (map), processing each, then combining results (reduce)", "Reducing the number of maps in a GPS app", "A data compression algorithm"], "answer": 1, "explanation": "The map-reduce pattern breaks large inputs into smaller chunks (map phase), processes each chunk with a focused prompt, then combines all chunk results into a final unified output (reduce phase). It handles inputs too large for a single context window."},
    {"id": "L7-086", "q": "When using AI for code documentation generation, a combined approach might include:", "options": ["Only generating comments and nothing else", "Asking the AI to make up what the code does", "CoT to analyze code logic, CRISP to structure the documentation, few-shot for format examples", "Generating documentation without reading the code"], "answer": 2, "explanation": "Effective documentation generation combines CoT (to analyze code logic step-by-step), CRISP (to structure the documentation requirements), and few-shot examples (to demonstrate the desired documentation format)."},
    {"id": "L7-087", "q": "What is the risk of over-relying on AI autocomplete in coding?", "options": ["The code will be too well-written", "Autocomplete makes code impossible to read", "There is no risk at all", "Developers may accept suggestions without fully understanding them, introducing subtle bugs"], "answer": 3, "explanation": "Over-reliance on AI autocomplete can lead developers to accept suggestions without fully understanding the code, potentially introducing subtle bugs, security vulnerabilities, or logic errors that are hard to catch later."},
    {"id": "L7-088", "q": "Claude Code's session-based architecture means:", "options": ["Each session starts fresh, relying on project files like CLAUDE.md for continuity", "It only works during business hours", "Sessions last exactly 60 minutes", "Only one person can use it at a time globally"], "answer": 0, "explanation": "Claude Code sessions start fresh without memory of previous sessions. Project files like CLAUDE.md and HANDOFF.md provide continuity by documenting project context, standards, and current state for each new session."},
    {"id": "L7-089", "q": "In a complex prompt chain for feature development, 'acceptance criteria' should be defined:", "options": ["After the feature is already deployed", "At the beginning of the chain, so every step works toward measurable goals", "Only by the AI, never by humans", "Acceptance criteria are not relevant to prompt chains"], "answer": 1, "explanation": "Defining acceptance criteria at the start of the chain ensures every subsequent step (design, implementation, testing) works toward measurable, verifiable goals — just like in traditional software development."},
    {"id": "L7-090", "q": "What is 'prompt injection' and why should AI IDE users be aware of it?", "options": ["Injecting vitamins into a prompt", "Adding more words to make a prompt longer", "Malicious instructions hidden in code or data that can hijack AI behavior", "A technique for faster prompt delivery"], "answer": 2, "explanation": "Prompt injection is when malicious instructions are hidden in code, comments, or data that the AI reads, potentially hijacking its behavior. AI IDE users should be aware because they regularly feed external code into AI systems."},
    {"id": "L7-091", "q": "When combining methods for error handling design, an effective prompt combines:", "options": ["No frameworks at all", "Role (senior developer), CRISP structure, CoT for reasoning through failure modes, examples of error patterns", "Only asking 'fix the errors'", "Copying error handling from an unrelated project"], "answer": 1, "explanation": "Effective error handling design combines an expert role for domain knowledge, CRISP for structured requirements, CoT to reason through all possible failure modes, and examples demonstrating the desired error handling patterns."},
    {"id": "L7-092", "q": "In AI-powered IDEs, 'workspace awareness' means the AI:", "options": ["Understands your project structure, dependencies, and file relationships", "Knows the physical layout of your office", "Is aware of your work schedule", "Can detect workspace temperature"], "answer": 0, "explanation": "Workspace awareness means the AI understands your project's file structure, dependencies between modules, imported packages, and how files relate to each other — enabling more contextually relevant suggestions."},
    {"id": "L7-093", "q": "A 'recursive refinement' prompt chain works by:", "options": ["Recursively deleting files", "Running the same prompt infinitely", "Having the AI improve its own output through multiple passes until quality criteria are met", "Making prompts shorter each iteration"], "answer": 2, "explanation": "Recursive refinement has the AI review and improve its own output through multiple passes, each time checking against quality criteria. The chain loops until the output meets the defined standard or a maximum iteration count is reached."},
    {"id": "L7-094", "q": "What is the advantage of using AI for code translation between programming languages?", "options": ["AI can handle syntax conversion and suggest idiomatic patterns in the target language", "AI perfectly translates all code without any issues", "Code translation is unnecessary because all languages are the same", "AI can only translate between Python and JavaScript"], "answer": 0, "explanation": "AI can convert syntax and suggest idiomatic patterns in the target language, going beyond literal translation. However, human review is still essential for edge cases, language-specific features, and performance characteristics."},
    {"id": "L7-095", "q": "When orchestrating a full-stack feature with prompt chaining, which is the correct layer order?", "options": ["Start with styling, then database, then API", "Database schema, API endpoints, business logic, frontend components, integration tests", "Start with deployment, then write the code", "Only build the frontend and skip the backend"], "answer": 1, "explanation": "Full-stack feature chains should flow from data layer up: database schema first, then API endpoints, then business logic, then frontend components, and finally integration tests — each layer building on the one below."},
    {"id": "L7-096", "q": "In Cursor, the 'Agent' mode differs from 'Ask' mode because it:", "options": ["Can only answer questions about Cursor itself", "Uses a less capable AI model", "Can autonomously execute multi-step tasks including file edits and terminal commands", "Only works offline"], "answer": 2, "explanation": "Cursor's Agent mode can autonomously plan and execute multi-step tasks — reading files, making edits, running terminal commands, and iterating — while Ask mode provides answers and suggestions without taking direct action."},
    {"id": "L7-097", "q": "What is 'output chaining' versus 'instruction chaining'?", "options": ["They are the same thing", "Output chaining passes results forward; instruction chaining builds up a complex instruction across steps", "Output chaining is for text; instruction chaining is for code", "Neither involves multiple prompts"], "answer": 1, "explanation": "Output chaining passes the output of one prompt as input to the next. Instruction chaining progressively builds up a complex, refined instruction across multiple steps before the final generation — both are valid chain strategies."},
    {"id": "L7-098", "q": "When using AI coding tools in a team environment, the most important practice is:", "options": ["Establishing shared AI usage guidelines, verification standards, and review processes", "Everyone should use the exact same prompts", "Only one team member should use AI tools", "Keeping AI usage secret from the team"], "answer": 0, "explanation": "Teams should establish shared guidelines for AI usage, including verification standards, code review processes for AI-generated code, and transparency about when AI assistance was used — ensuring consistent quality and trust."},
    {"id": "L7-099", "q": "What is the 'sandwich technique' in complex prompting?", "options": ["Placing critical instructions at both the beginning and end of a prompt to ensure they are followed", "Making a sandwich while waiting for AI responses", "Layering three different AI models", "Using exactly three sentences in every prompt"], "answer": 0, "explanation": "The sandwich technique places critical instructions at both the beginning and end of a long prompt. AI models pay more attention to the start and end of inputs, so repeating key constraints in both positions improves compliance."},
    {"id": "L7-100", "q": "The ultimate goal of mastering prompt engineering for coding is to:", "options": ["Replace the need for programming knowledge", "Eliminate all software bugs automatically", "Amplify developer capability while maintaining human oversight and code quality", "Make AI do all the work without human involvement"], "answer": 2, "explanation": "Mastering prompt engineering amplifies developer capability — making you faster, more thorough, and able to tackle complex tasks. But human oversight, code quality standards, and verification remain essential for reliable software."}
  ]
}
